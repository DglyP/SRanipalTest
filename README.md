# Project Title: Investigating Pupil Mimicry in Human Interaction with Virtual Avatars and Robots

## Overview
The purpose of this project is to investigate whether humans exhibit pupil mimicry when they interact with virtual avatars or robots that have the ability to change the size of their pupils. Pupil size is a crucial social signal connected with understanding emotions and joint emotional responses. By examining the evidence for pupil mimicry, this project aims to explore its effects on the perception of these entities as human-like, its social implications for humans, and its potential impact on the development of realistic virtual and robotic technologies.

## Research Techniques
- The Godspeed questionnaire: A standardized questionnaire to measure subjective perceptions of human-likeness and emotional responses.
- Likert scales: A rating scale used to assess subjective perceptions of different aspects related to pupil mimicry.
- Fixation objects: Visual stimuli used to study gaze behavior and eye movement patterns during interaction with virtual avatars and robots.

## Technologies Used
- Sranipal SDK: Software development kit provided by HTC for eye tracking on Vive Pro Eye. It enables precise measurement and analysis of eye movements, including pupil size changes and gaze tracking.
- Vive Focus 3: Virtual reality headset used to study human interaction with virtual avatars and robots. With its powerful hardware capabilities, it provides an immersive experience for participants.
- Vive Pro Eye: Eye-tracking virtual reality headset used to collect high-resolution pupil data during interaction. The eye tracking capabilities allow for detailed analysis of pupil dilation and movement.
- Unity 3D Game Engine: Development platform used for creating immersive virtual environments and simulations. Unity provides a robust framework for implementing the virtual avatar and robot interactions, integrating eye tracking data, and creating realistic 3D visualizations.

## Eye Tracking Implementation
The Sranipal SDK offers a comprehensive set of APIs for accessing eye tracking data from the Vive Pro Eye headset. By integrating the SDK with Unity, we can accurately track and analyze participants' eye movements, including pupil dilation, gaze direction, and fixations. This eye tracking data is instrumental in understanding how humans interact with virtual avatars and robots and evaluating the presence of pupil mimicry.

Usage and Experimentation
Participants in the study will wear the Vive Pro Eye headset, which tracks their eye movements in real-time. They will interact with virtual avatars and robots in various scenarios while their eye movements and pupil size changes are recorded. The Godspeed questionnaire and Likert scales will be employed to gather subjective feedback on the perception of human-likeness and emotional responses.

Potential Implications
The results of this study may have significant implications for the development of more realistic virtual humanoids that can better elicit emotional responses and improve the interaction between real and artificial humans. By understanding the role of pupil mimicry in human perception, developers can enhance the design and behavior of virtual avatars and robots to create more engaging and socially responsive experiences.

Investigation Areas
- Role of blinking: Analyzing the relationship between pupil data and blinking patterns during human interaction. This investigation will provide insights into how blinking affects the perception of virtual avatars and robots.
- Importance of brightness perception: Investigating the impact of brightness perception and luminance manipulation on pupil research. This exploration will shed light on how changes in brightness and lighting conditions influence pupil size changes and emotional responses.

Contributions
Contributions to this project are welcome. If you have expertise or insights related to pupil mimicry, emotional responses, virtual humanoids, eye tracking, or related areas, feel free to reach out and contribute to the research.

License
This project is licensed under the [MIT License]. Please see the LICENSE file for more details.

Acknowledgments
We would like to express our gratitude to the participants of this study, as well as the researchers, developers, and companies such as HTC and Unity Technologies who have contributed to the fields of virtual reality, eye-tracking technology, and human-computer interaction.
